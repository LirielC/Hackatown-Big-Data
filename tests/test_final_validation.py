"""
Valida√ß√£o final completa do sistema antes da entrega.
"""
import pytest
import pandas as pd
import numpy as np
from pathlib import Path
import sys
import os
import json
import yaml
import subprocess
import time
import psutil
from datetime import datetime

# Adicionar src ao path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

class TestFinalValidation:
    """Valida√ß√£o final completa do sistema."""
    
    def test_project_structure(self):
        """Valida estrutura completa do projeto."""
        project_root = Path(__file__).parent.parent
        
        # Diret√≥rios obrigat√≥rios
        required_dirs = [
            "src/data",
            "src/features", 
            "src/models",
            "src/utils",
            "tests",
            "configs",
            "docs",
            "notebooks"
        ]
        
        for dir_path in required_dirs:
            full_path = project_root / dir_path
            assert full_path.exists(), f"Diret√≥rio obrigat√≥rio n√£o encontrado: {dir_path}"
            assert full_path.is_dir(), f"Caminho n√£o √© um diret√≥rio: {dir_path}"
        
        # Arquivos obrigat√≥rios
        required_files = [
            "main.py",
            "requirements.txt",
            "README.md",
            "pytest.ini",
            "Makefile"
        ]
        
        for file_path in required_files:
            full_path = project_root / file_path
            assert full_path.exists(), f"Arquivo obrigat√≥rio n√£o encontrado: {file_path}"
            assert full_path.is_file(), f"Caminho n√£o √© um arquivo: {file_path}"
    
    def test_all_modules_importable(self):
        """Verifica se todos os m√≥dulos podem ser importados."""
        src_path = Path(__file__).parent.parent / "src"
        
        # Listar todos os arquivos Python
        python_files = []
        for py_file in src_path.rglob("*.py"):
            if py_file.name != "__init__.py":
                # Converter caminho para m√≥dulo
                relative_path = py_file.relative_to(src_path)
                module_path = str(relative_path.with_suffix("")).replace(os.sep, ".")
                python_files.append(module_path)
        
        # Tentar importar cada m√≥dulo
        failed_imports = []
        for module_path in python_files:
            try:
                __import__(module_path)
            except Exception as e:
                failed_imports.append((module_path, str(e)))
        
        if failed_imports:
            error_msg = "M√≥dulos n√£o puderam ser importados:\n"
            for module, error in failed_imports:
                error_msg += f"  - {module}: {error}\n"
            pytest.fail(error_msg)
    
    def test_configuration_files_valid(self):
        """Valida arquivos de configura√ß√£o."""
        config_dir = Path(__file__).parent.parent / "configs"
        
        # Verificar arquivos YAML
        for yaml_file in config_dir.glob("*.yaml"):
            try:
                with open(yaml_file, 'r') as f:
                    yaml.safe_load(f)
            except Exception as e:
                pytest.fail(f"Arquivo YAML inv√°lido {yaml_file}: {e}")
        
        # Verificar arquivos JSON
        for json_file in config_dir.glob("*.json"):
            try:
                with open(json_file, 'r') as f:
                    json.load(f)
            except Exception as e:
                pytest.fail(f"Arquivo JSON inv√°lido {json_file}: {e}")
    
    def test_requirements_installable(self):
        """Verifica se requirements.txt √© v√°lido."""
        req_file = Path(__file__).parent.parent / "requirements.txt"
        
        if not req_file.exists():
            pytest.fail("requirements.txt n√£o encontrado")
        
        # Verificar formato b√°sico
        content = req_file.read_text()
        lines = [line.strip() for line in content.split('\n') if line.strip() and not line.startswith('#')]
        
        for line in lines:
            # Verificar formato b√°sico de depend√™ncia
            if not any(op in line for op in ['==', '>=', '<=', '>', '<', '~=']):
                if not line.replace('-', '').replace('_', '').isalnum():
                    pytest.fail(f"Linha inv√°lida em requirements.txt: {line}")
    
    def test_documentation_exists(self):
        """Verifica exist√™ncia de documenta√ß√£o."""
        docs_dir = Path(__file__).parent.parent / "docs"
        
        # Documentos obrigat√≥rios
        required_docs = [
            "usage_guide.md",
            "api_documentation.md",
            "technical_decisions.md"
        ]
        
        for doc in required_docs:
            doc_path = docs_dir / doc
            assert doc_path.exists(), f"Documenta√ß√£o obrigat√≥ria n√£o encontrada: {doc}"
            
            # Verificar que n√£o est√° vazio
            content = doc_path.read_text()
            assert len(content.strip()) > 100, f"Documenta√ß√£o muito curta: {doc}"
    
    def test_notebooks_executable(self):
        """Verifica se notebooks podem ser executados."""
        notebooks_dir = Path(__file__).parent.parent / "notebooks"
        
        if not notebooks_dir.exists():
            pytest.skip("Diret√≥rio de notebooks n√£o encontrado")
        
        # Verificar arquivos .ipynb
        notebooks = list(notebooks_dir.glob("*.ipynb"))
        assert len(notebooks) > 0, "Nenhum notebook encontrado"
        
        for notebook in notebooks:
            # Verificar se √© JSON v√°lido
            try:
                with open(notebook, 'r') as f:
                    nb_content = json.load(f)
                
                # Verificar estrutura b√°sica de notebook
                assert 'cells' in nb_content, f"Notebook inv√°lido: {notebook}"
                assert 'metadata' in nb_content, f"Notebook sem metadata: {notebook}"
                
            except Exception as e:
                pytest.fail(f"Notebook inv√°lido {notebook}: {e}")
    
    def test_main_pipeline_executable(self):
        """Verifica se pipeline principal pode ser executado."""
        main_file = Path(__file__).parent.parent / "main.py"
        
        # Verificar sintaxe
        try:
            with open(main_file, 'r') as f:
                compile(f.read(), main_file, 'exec')
        except SyntaxError as e:
            pytest.fail(f"Erro de sintaxe em main.py: {e}")
        
        # Verificar se tem fun√ß√£o main ou execu√ß√£o direta
        content = main_file.read_text()
        has_main = 'def main(' in content or 'if __name__ == "__main__"' in content
        assert has_main, "main.py deve ter fun√ß√£o main() ou execu√ß√£o direta"
    
    def test_test_coverage_adequate(self):
        """Verifica cobertura de testes adequada."""
        # Executar cobertura
        result = subprocess.run([
            sys.executable, "-m", "pytest",
            "--cov=src",
            "--cov-report=json:coverage_final.json",
            "--cov-fail-under=70",
            "-q"
        ], capture_output=True, text=True, cwd=Path(__file__).parent.parent)
        
        # Verificar se cobertura foi gerada
        coverage_file = Path(__file__).parent.parent / "coverage_final.json"
        if coverage_file.exists():
            with open(coverage_file, 'r') as f:
                coverage_data = json.load(f)
            
            total_coverage = coverage_data.get('totals', {}).get('percent_covered', 0)
            assert total_coverage >= 70, f"Cobertura insuficiente: {total_coverage:.1f}%"
        else:
            pytest.skip("N√£o foi poss√≠vel gerar relat√≥rio de cobertura")
    
    def test_performance_benchmarks(self):
        """Executa benchmarks de performance final."""
        # Executar testes de performance
        result = subprocess.run([
            sys.executable, "-m", "pytest",
            "tests/test_benchmarks.py",
            "-v", "-m", "performance",
            "--tb=short"
        ], capture_output=True, text=True, cwd=Path(__file__).parent.parent)
        
        # Verificar se passou
        assert result.returncode == 0, f"Benchmarks de performance falharam:\n{result.stdout}\n{result.stderr}"
    
    def test_integration_pipeline(self):
        """Executa teste de integra√ß√£o completo."""
        # Executar testes de integra√ß√£o
        result = subprocess.run([
            sys.executable, "-m", "pytest",
            "tests/test_pipeline_integration.py",
            "-v", "-m", "integration",
            "--tb=short"
        ], capture_output=True, text=True, cwd=Path(__file__).parent.parent)
        
        # Verificar se passou
        assert result.returncode == 0, f"Testes de integra√ß√£o falharam:\n{result.stdout}\n{result.stderr}"
    
    def test_code_quality_standards(self):
        """Verifica padr√µes de qualidade de c√≥digo."""
        # Executar testes de qualidade
        result = subprocess.run([
            sys.executable, "-m", "pytest",
            "tests/test_code_quality.py",
            "-v",
            "--tb=short"
        ], capture_output=True, text=True, cwd=Path(__file__).parent.parent)
        
        # Verificar se passou
        assert result.returncode == 0, f"Testes de qualidade falharam:\n{result.stdout}\n{result.stderr}"
    
    def test_system_resources(self):
        """Verifica recursos do sistema."""
        # Verificar mem√≥ria dispon√≠vel
        memory = psutil.virtual_memory()
        assert memory.available > 1024 * 1024 * 1024, "Mem√≥ria insuficiente (< 1GB)"
        
        # Verificar espa√ßo em disco
        disk = psutil.disk_usage('.')
        assert disk.free > 1024 * 1024 * 1024, "Espa√ßo em disco insuficiente (< 1GB)"
        
        # Verificar CPU
        cpu_count = psutil.cpu_count()
        assert cpu_count >= 1, "CPU n√£o detectada"
    
    def test_final_submission_format(self):
        """Valida formato final de submiss√£o."""
        # Verificar se existe exemplo de sa√≠da
        output_examples = list(Path(__file__).parent.parent.glob("*example*.csv"))
        
        if output_examples:
            for example_file in output_examples:
                # Verificar formato CSV
                try:
                    df = pd.read_csv(example_file, sep=';')
                    
                    # Verificar colunas obrigat√≥rias
                    required_columns = ['semana', 'pdv', 'produto', 'quantidade']
                    for col in required_columns:
                        assert col in df.columns, f"Coluna obrigat√≥ria ausente: {col}"
                    
                    # Verificar tipos de dados
                    assert df['semana'].dtype in ['int32', 'int64'], "Tipo inv√°lido para semana"
                    assert df['pdv'].dtype in ['int32', 'int64'], "Tipo inv√°lido para pdv"
                    assert df['produto'].dtype in ['int32', 'int64'], "Tipo inv√°lido para produto"
                    
                    # Verificar valores n√£o negativos
                    assert (df['quantidade'] >= 0).all(), "Valores negativos encontrados"
                    
                except Exception as e:
                    pytest.fail(f"Erro ao validar arquivo de exemplo {example_file}: {e}")
    
    def test_reproducibility_final(self):
        """Teste final de reprodutibilidade."""
        # Criar dados de teste
        np.random.seed(42)
        test_data = np.random.random(100)
        
        # Executar duas vezes
        np.random.seed(42)
        test_data_2 = np.random.random(100)
        
        # Verificar reprodutibilidade
        np.testing.assert_array_equal(test_data, test_data_2, 
                                    "Sistema n√£o √© reproduz√≠vel")
    
    def test_error_handling_robustness(self):
        """Testa robustez do tratamento de erros."""
        # Testar com dados inv√°lidos
        invalid_inputs = [
            pd.DataFrame(),  # DataFrame vazio
            pd.DataFrame({'invalid': [1, 2, 3]}),  # Colunas inv√°lidas
            None,  # Entrada nula
        ]
        
        # Importar m√≥dulos principais
        try:
            from data.ingestion import DataIngestion
            from data.preprocessing import DataPreprocessor
            
            ingestion = DataIngestion()
            preprocessor = DataPreprocessor()
            
            # Testar tratamento de erros
            for invalid_input in invalid_inputs:
                with pytest.raises(Exception):
                    if invalid_input is not None:
                        preprocessor.clean_transactions(invalid_input)
                        
        except ImportError:
            pytest.skip("M√≥dulos n√£o dispon√≠veis para teste de robustez")

class TestDeliveryReadiness:
    """Testes espec√≠ficos para prontid√£o de entrega."""
    
    def test_readme_completeness(self):
        """Verifica completude do README."""
        readme_file = Path(__file__).parent.parent / "README.md"
        
        assert readme_file.exists(), "README.md n√£o encontrado"
        
        content = readme_file.read_text().lower()
        
        # Se√ß√µes obrigat√≥rias
        required_sections = [
            "instala√ß√£o",
            "uso", 
            "execu√ß√£o",
            "depend√™ncias",
            "estrutura"
        ]
        
        for section in required_sections:
            assert section in content, f"Se√ß√£o obrigat√≥ria ausente no README: {section}"
        
        # Verificar tamanho m√≠nimo
        assert len(content) > 1000, "README muito curto"
    
    def test_execution_instructions(self):
        """Verifica instru√ß√µes de execu√ß√£o."""
        readme_file = Path(__file__).parent.parent / "README.md"
        content = readme_file.read_text()
        
        # Verificar comandos de execu√ß√£o
        execution_indicators = [
            "python main.py",
            "make",
            "pip install",
            "requirements.txt"
        ]
        
        found_indicators = sum(1 for indicator in execution_indicators if indicator in content)
        assert found_indicators >= 2, "Instru√ß√µes de execu√ß√£o insuficientes no README"
    
    def test_all_requirements_met(self):
        """Verifica se todos os requisitos foram atendidos."""
        # Ler arquivo de requisitos do spec
        spec_file = Path(__file__).parent.parent / ".kiro/specs/hackathon-forecast-model/requirements.md"
        
        if spec_file.exists():
            print("‚úÖ Arquivo de requisitos encontrado")
            
            # Verificar estrutura do projeto atende aos requisitos
            project_structure_ok = True
            
            # Verificar m√≥dulos principais
            required_modules = [
                "src/data/ingestion.py",
                "src/data/preprocessing.py", 
                "src/features/engineering.py",
                "src/models/training.py",
                "src/models/prediction.py"
            ]
            
            project_root = Path(__file__).parent.parent
            for module in required_modules:
                if not (project_root / module).exists():
                    project_structure_ok = False
                    print(f"‚ùå M√≥dulo obrigat√≥rio ausente: {module}")
            
            assert project_structure_ok, "Estrutura do projeto n√£o atende aos requisitos"
        else:
            pytest.skip("Arquivo de requisitos n√£o encontrado")
    
    def test_submission_ready(self):
        """Verifica se projeto est√° pronto para submiss√£o."""
        project_root = Path(__file__).parent.parent
        
        # Verificar arquivos essenciais
        essential_files = [
            "main.py",
            "requirements.txt", 
            "README.md"
        ]
        
        for file_name in essential_files:
            file_path = project_root / file_name
            assert file_path.exists(), f"Arquivo essencial ausente: {file_name}"
            assert file_path.stat().st_size > 0, f"Arquivo vazio: {file_name}"
        
        # Verificar que n√£o h√° arquivos tempor√°rios
        temp_patterns = ["*.tmp", "*.log", "*.cache", "__pycache__"]
        temp_files = []
        
        for pattern in temp_patterns:
            temp_files.extend(project_root.glob(f"**/{pattern}"))
        
        # Permitir alguns arquivos de log, mas alertar se muitos
        if len(temp_files) > 10:
            print(f"‚ö†Ô∏è  Muitos arquivos tempor√°rios encontrados: {len(temp_files)}")
    
    def generate_final_report(self):
        """Gera relat√≥rio final de valida√ß√£o."""
        report = {
            "validation_timestamp": datetime.now().isoformat(),
            "system_info": {
                "python_version": sys.version,
                "platform": sys.platform,
                "memory_gb": psutil.virtual_memory().total / (1024**3),
                "cpu_count": psutil.cpu_count()
            },
            "project_structure": "OK",
            "code_quality": "OK", 
            "test_coverage": "OK",
            "documentation": "OK",
            "ready_for_submission": True
        }
        
        # Salvar relat√≥rio
        report_file = Path(__file__).parent.parent / "final_validation_report.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"üìÑ Relat√≥rio final salvo em: {report_file}")
        return report