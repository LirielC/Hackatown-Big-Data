{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering e Análise - Hackathon Forecast 2025\n",
    "\n",
    "Este notebook implementa e analisa as features para o modelo de previsão de vendas, incluindo features temporais, de lag, estatísticas móveis e seleção de features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importar módulos do projeto\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from data.ingestion import DataIngestion\n",
    "from data.preprocessing import DataPreprocessor\n",
    "from features.engineering import FeatureEngineer\n",
    "from features.selection import FeatureSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento e Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar e processar dados\n",
    "ingestion = DataIngestion()\n",
    "preprocessor = DataPreprocessor()\n",
    "feature_engineer = FeatureEngineer()\n",
    "feature_selector = FeatureSelector()\n",
    "\n",
    "print(\"Carregando dados...\")\n",
    "transactions_df = ingestion.load_transactions('../hackathon_2025_templates/')\n",
    "products_df = ingestion.load_products('../hackathon_2025_templates/')\n",
    "stores_df = ingestion.load_stores('../hackathon_2025_templates/')\n",
    "\n",
    "print(\"Processando dados...\")\n",
    "transactions_clean = preprocessor.clean_transactions(transactions_df)\n",
    "weekly_sales = preprocessor.aggregate_weekly_sales(transactions_clean)\n",
    "merged_data = preprocessor.merge_master_data(weekly_sales, products_df, stores_df)\n",
    "\n",
    "print(f\"Dados base: {merged_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Engenharia de Features Temporais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar features temporais\n",
    "print(\"Criando features temporais...\")\n",
    "temporal_features = feature_engineer.create_temporal_features(merged_data)\n",
    "\n",
    "print(f\"Features temporais criadas: {temporal_features.shape}\")\n",
    "print(\"\\nNovas colunas temporais:\")\n",
    "temporal_cols = [col for col in temporal_features.columns if col not in merged_data.columns]\n",
    "for col in temporal_cols:\n",
    "    print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribuição das features temporais\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=3,\n",
    "    subplot_titles=('Semana do Ano', 'Mês', 'Trimestre', \n",
    "                   'Dia da Semana', 'É Início de Mês', 'É Fim de Mês')\n",
    ")\n",
    "\n",
    "# Semana do ano\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=temporal_features['semana_ano'], name='Semana'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Mês\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=temporal_features['mes'], name='Mês'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Trimestre\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=temporal_features['trimestre'], name='Trimestre'),\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "# Dia da semana\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=temporal_features['dia_semana'], name='Dia Semana'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Início de mês\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=temporal_features['inicio_mes'], name='Início Mês'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Fim de mês\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=temporal_features['fim_mes'], name='Fim Mês'),\n",
    "    row=2, col=3\n",
    ")\n",
    "\n",
    "fig.update_layout(height=600, title_text=\"Distribuição das Features Temporais\", showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Features de Produto e PDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar features de produto\n",
    "print(\"Criando features de produto...\")\n",
    "product_features = feature_engineer.create_product_features(temporal_features)\n",
    "\n",
    "print(f\"Features de produto: {product_features.shape}\")\n",
    "product_cols = [col for col in product_features.columns if col not in temporal_features.columns]\n",
    "print(\"\\nNovas features de produto:\")\n",
    "for col in product_cols:\n",
    "    print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar features de PDV\n",
    "print(\"Criando features de PDV...\")\n",
    "store_features = feature_engineer.create_store_features(product_features)\n",
    "\n",
    "print(f\"Features de PDV: {store_features.shape}\")\n",
    "store_cols = [col for col in store_features.columns if col not in product_features.columns]\n",
    "print(\"\\nNovas features de PDV:\")\n",
    "for col in store_cols:\n",
    "    print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Features de Lag e Estatísticas Móveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar features de lag\n",
    "print(\"Criando features de lag...\")\n",
    "lag_features = feature_engineer.create_lag_features(store_features)\n",
    "\n",
    "print(f\"Features com lag: {lag_features.shape}\")\n",
    "lag_cols = [col for col in lag_features.columns if 'lag_' in col or 'ma_' in col or 'std_' in col]\n",
    "print(f\"\\nFeatures de lag criadas ({len(lag_cols)}):\")\n",
    "for col in lag_cols[:10]:  # Mostrar apenas as primeiras 10\n",
    "    print(f\"- {col}\")\n",
    "if len(lag_cols) > 10:\n",
    "    print(f\"... e mais {len(lag_cols) - 10} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar correlação entre lags\n",
    "lag_correlation = lag_features[lag_cols].corr()\n",
    "\n",
    "fig = px.imshow(\n",
    "    lag_correlation,\n",
    "    title=\"Correlação entre Features de Lag\",\n",
    "    aspect=\"auto\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análise de Importância das Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados para análise de importância\n",
    "# Remover linhas com NaN (devido aos lags)\n",
    "analysis_data = lag_features.dropna()\n",
    "\n",
    "# Separar features numéricas\n",
    "numeric_features = analysis_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if 'quantidade' in numeric_features:\n",
    "    numeric_features.remove('quantidade')\n",
    "\n",
    "X = analysis_data[numeric_features]\n",
    "y = analysis_data['quantidade']\n",
    "\n",
    "print(f\"Dados para análise: {X.shape}\")\n",
    "print(f\"Features numéricas: {len(numeric_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular importância com Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Criar DataFrame com importâncias\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Visualizar top 20 features mais importantes\n",
    "top_features = feature_importance.head(20)\n",
    "\n",
    "fig = px.bar(\n",
    "    top_features,\n",
    "    x='importance',\n",
    "    y='feature',\n",
    "    orientation='h',\n",
    "    title=\"Top 20 Features Mais Importantes (Random Forest)\"\n",
    ")\n",
    "fig.update_layout(height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Seleção de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar diferentes métodos de seleção\n",
    "print(\"Aplicando seleção de features...\")\n",
    "\n",
    "# Método 1: SelectKBest\n",
    "selector_kbest = SelectKBest(score_func=f_regression, k=50)\n",
    "X_kbest = selector_kbest.fit_transform(X, y)\n",
    "selected_features_kbest = X.columns[selector_kbest.get_support()]\n",
    "\n",
    "print(f\"SelectKBest: {len(selected_features_kbest)} features selecionadas\")\n",
    "\n",
    "# Método 2: RFE com Random Forest\n",
    "rfe = RFE(estimator=RandomForestRegressor(n_estimators=50, random_state=42), n_features_to_select=50)\n",
    "X_rfe = rfe.fit_transform(X, y)\n",
    "selected_features_rfe = X.columns[rfe.support_]\n",
    "\n",
    "print(f\"RFE: {len(selected_features_rfe)} features selecionadas\")\n",
    "\n",
    "# Método 3: Baseado em importância do Random Forest\n",
    "threshold = feature_importance['importance'].quantile(0.8)  # Top 20%\n",
    "selected_features_rf = feature_importance[feature_importance['importance'] >= threshold]['feature'].tolist()\n",
    "\n",
    "print(f\"RF Importance: {len(selected_features_rf)} features selecionadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar métodos de seleção\n",
    "methods_comparison = pd.DataFrame({\n",
    "    'Método': ['SelectKBest', 'RFE', 'RF Importance'],\n",
    "    'Num Features': [len(selected_features_kbest), len(selected_features_rfe), len(selected_features_rf)]\n",
    "})\n",
    "\n",
    "fig = px.bar(\n",
    "    methods_comparison,\n",
    "    x='Método',\n",
    "    y='Num Features',\n",
    "    title=\"Comparação dos Métodos de Seleção de Features\"\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Encontrar features comuns\n",
    "common_features = set(selected_features_kbest) & set(selected_features_rfe) & set(selected_features_rf)\n",
    "print(f\"\\nFeatures selecionadas por todos os métodos: {len(common_features)}\")\n",
    "print(\"Features comuns:\")\n",
    "for feature in sorted(common_features):\n",
    "    print(f\"- {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análise de Correlação das Features Selecionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisar correlação das features mais importantes\n",
    "top_30_features = feature_importance.head(30)['feature'].tolist()\n",
    "correlation_matrix = X[top_30_features].corr()\n",
    "\n",
    "fig = px.imshow(\n",
    "    correlation_matrix,\n",
    "    title=\"Matriz de Correlação - Top 30 Features\",\n",
    "    aspect=\"auto\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar features altamente correlacionadas\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_value = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_value) > 0.8:  # Correlação alta\n",
    "            high_corr_pairs.append({\n",
    "                'Feature 1': correlation_matrix.columns[i],\n",
    "                'Feature 2': correlation_matrix.columns[j],\n",
    "                'Correlação': corr_value\n",
    "            })\n",
    "\n",
    "if high_corr_pairs:\n",
    "    high_corr_df = pd.DataFrame(high_corr_pairs).sort_values('Correlação', key=abs, ascending=False)\n",
    "    print(\"Features com alta correlação (>0.8):\")\n",
    "    print(high_corr_df)\n",
    "else:\n",
    "    print(\"Nenhuma correlação alta encontrada entre as top features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Análise de Distribuição das Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisar distribuição das top features\n",
    "top_10_features = feature_importance.head(10)['feature'].tolist()\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=5,\n",
    "    subplot_titles=top_10_features\n",
    ")\n",
    "\n",
    "for i, feature in enumerate(top_10_features):\n",
    "    row = (i // 5) + 1\n",
    "    col = (i % 5) + 1\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Histogram(x=X[feature], name=feature, showlegend=False),\n",
    "        row=row, col=col\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=600, title_text=\"Distribuição das Top 10 Features\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Engineering Avançado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar features de interação\n",
    "print(\"Criando features de interação...\")\n",
    "\n",
    "# Interações entre top features\n",
    "interaction_features = analysis_data.copy()\n",
    "\n",
    "# Exemplo: interação entre categoria e tipo de PDV\n",
    "if 'categoria_produto_encoded' in interaction_features.columns and 'tipo_pdv_encoded' in interaction_features.columns:\n",
    "    interaction_features['categoria_x_tipo_pdv'] = (\n",
    "        interaction_features['categoria_produto_encoded'] * interaction_features['tipo_pdv_encoded']\n",
    "    )\n",
    "\n",
    "# Interação entre lag e sazonalidade\n",
    "if 'lag_1' in interaction_features.columns and 'semana_ano' in interaction_features.columns:\n",
    "    interaction_features['lag1_x_semana'] = (\n",
    "        interaction_features['lag_1'] * interaction_features['semana_ano']\n",
    "    )\n",
    "\n",
    "print(f\"Features com interações: {interaction_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Resumo e Recomendações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo final\n",
    "print(\"=== RESUMO DA ENGENHARIA DE FEATURES ===\")\n",
    "print(f\"\\nDados originais: {merged_data.shape}\")\n",
    "print(f\"Features finais: {lag_features.shape}\")\n",
    "print(f\"Features numéricas: {len(numeric_features)}\")\n",
    "\n",
    "print(\"\\n=== TOP 10 FEATURES MAIS IMPORTANTES ===\")\n",
    "for i, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"{i+1:2d}. {row['feature']:<25} ({row['importance']:.4f})\")\n",
    "\n",
    "print(\"\\n=== RECOMENDAÇÕES ===\")\n",
    "print(\"1. Usar features de lag como principais preditores\")\n",
    "print(\"2. Incluir features temporais para capturar sazonalidade\")\n",
    "print(\"3. Considerar features de produto e PDV para segmentação\")\n",
    "print(\"4. Aplicar seleção de features para reduzir overfitting\")\n",
    "print(\"5. Monitorar correlações altas entre features\")\n",
    "\n",
    "print(\"\\n=== PRÓXIMOS PASSOS ===\")\n",
    "print(\"1. Testar diferentes janelas de lag\")\n",
    "print(\"2. Experimentar transformações (log, sqrt)\")\n",
    "print(\"3. Criar features de interação mais complexas\")\n",
    "print(\"4. Validar features com cross-validation temporal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar features processadas para uso nos modelos\n",
    "print(\"Salvando features processadas...\")\n",
    "lag_features.to_parquet('../data/processed/features_engineered.parquet')\n",
    "feature_importance.to_csv('../data/processed/feature_importance.csv', index=False)\n",
    "\n",
    "# Salvar lista de features selecionadas\n",
    "pd.Series(list(common_features)).to_csv('../data/processed/selected_features.csv', index=False, header=['feature'])\n",
    "\n",
    "print(\"Features salvas com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}