{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Resultados - Hackathon Forecast 2025\n",
    "\n",
    "Este notebook analisa os resultados finais do modelo, incluindo previsões, performance por segmento, análise de erros e insights para melhorias futuras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importar módulos do projeto\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from models.prediction import ModelPredictor\n",
    "from models.validation import ModelValidator\n",
    "from models.output_formatter import OutputFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento de Dados e Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados processados\n",
    "print(\"Carregando dados e modelos...\")\n",
    "\n",
    "# Dados\n",
    "features_df = pd.read_parquet('../data/processed/features_engineered.parquet')\n",
    "model_results = pd.read_csv('../data/processed/model_comparison_results.csv')\n",
    "feature_importance = pd.read_csv('../data/processed/final_feature_importance.csv')\n",
    "\n",
    "# Modelo treinado\n",
    "best_model = joblib.load('../models/best_xgb_model.pkl')\n",
    "\n",
    "# Configurações\n",
    "with open('../configs/best_model_config.json', 'r') as f:\n",
    "    model_config = json.load(f)\n",
    "\n",
    "print(f\"Dados carregados: {features_df.shape}\")\n",
    "print(f\"Melhor modelo: {model_config['model_type']}\")\n",
    "print(f\"Performance: WMAPE = {model_config['performance']['WMAPE']:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análise de Performance Geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar comparação de modelos\n",
    "fig = px.bar(\n",
    "    model_results.sort_values('WMAPE'),\n",
    "    x='Modelo',\n",
    "    y='WMAPE',\n",
    "    title=\"Comparação de Performance dos Modelos (WMAPE)\",\n",
    "    color='WMAPE',\n",
    "    color_continuous_scale='RdYlBu_r'\n",
    ")\n",
    "fig.update_layout(height=500)\n",
    "fig.show()\n",
    "\n",
    "# Tabela de resultados\n",
    "print(\"\\nResultados Detalhados:\")\n",
    "print(model_results.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análise de Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top features mais importantes\n",
    "top_features = feature_importance.head(15)\n",
    "\n",
    "fig = px.bar(\n",
    "    top_features,\n",
    "    x='importance',\n",
    "    y='feature',\n",
    "    orientation='h',\n",
    "    title=\"Top 15 Features Mais Importantes\",\n",
    "    color='importance',\n",
    "    color_continuous_scale='viridis'\n",
    ")\n",
    "fig.update_layout(height=600)\n",
    "fig.show()\n",
    "\n",
    "# Análise por tipo de feature\n",
    "feature_types = []\n",
    "for feature in feature_importance['feature']:\n",
    "    if 'lag_' in feature:\n",
    "        feature_types.append('Lag')\n",
    "    elif 'ma_' in feature or 'std_' in feature:\n",
    "        feature_types.append('Estatística Móvel')\n",
    "    elif any(temporal in feature for temporal in ['semana', 'mes', 'trimestre', 'dia']):\n",
    "        feature_types.append('Temporal')\n",
    "    elif 'produto' in feature or 'categoria' in feature:\n",
    "        feature_types.append('Produto')\n",
    "    elif 'pdv' in feature or 'tipo' in feature:\n",
    "        feature_types.append('PDV')\n",
    "    else:\n",
    "        feature_types.append('Outros')\n",
    "\n",
    "feature_importance['tipo'] = feature_types\n",
    "\n",
    "# Importância por tipo\n",
    "importance_by_type = feature_importance.groupby('tipo')['importance'].sum().sort_values(ascending=False)\n",
    "\n",
    "fig = px.pie(\n",
    "    values=importance_by_type.values,\n",
    "    names=importance_by_type.index,\n",
    "    title=\"Distribuição de Importância por Tipo de Feature\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Análise de Previsões por Segmento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados para análise\n",
    "analysis_data = features_df.dropna()\n",
    "X = analysis_data[model_config['features']]\n",
    "y_true = analysis_data['quantidade']\n",
    "y_pred = best_model.predict(X)\n",
    "\n",
    "# Adicionar previsões aos dados\n",
    "analysis_data = analysis_data.copy()\n",
    "analysis_data['predicao'] = y_pred\n",
    "analysis_data['erro_absoluto'] = np.abs(y_true - y_pred)\n",
    "analysis_data['erro_percentual'] = np.abs((y_true - y_pred) / y_true) * 100\n",
    "\n",
    "print(f\"Dados para análise: {analysis_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance por categoria de produto\n",
    "if 'categoria_produto' in analysis_data.columns:\n",
    "    perf_categoria = analysis_data.groupby('categoria_produto').agg({\n",
    "        'quantidade': ['count', 'mean'],\n",
    "        'erro_absoluto': 'mean',\n",
    "        'erro_percentual': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    perf_categoria.columns = ['Num_Registros', 'Venda_Media', 'MAE', 'MAPE']\n",
    "    perf_categoria = perf_categoria.sort_values('MAE', ascending=False)\n",
    "    \n",
    "    print(\"Performance por Categoria de Produto:\")\n",
    "    print(perf_categoria.head(10))\n",
    "    \n",
    "    # Visualizar\n",
    "    fig = px.scatter(\n",
    "        perf_categoria.reset_index(),\n",
    "        x='Venda_Media',\n",
    "        y='MAE',\n",
    "        size='Num_Registros',\n",
    "        hover_data=['categoria_produto', 'MAPE'],\n",
    "        title=\"Performance por Categoria: Venda Média vs MAE\"\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance por tipo de PDV\n",
    "if 'tipo_pdv' in analysis_data.columns:\n",
    "    perf_pdv = analysis_data.groupby('tipo_pdv').agg({\n",
    "        'quantidade': ['count', 'mean'],\n",
    "        'erro_absoluto': 'mean',\n",
    "        'erro_percentual': 'mean'\n",
    "    }).round(2)\n",
    "    \n",
    "    perf_pdv.columns = ['Num_Registros', 'Venda_Media', 'MAE', 'MAPE']\n",
    "    \n",
    "    print(\"\\nPerformance por Tipo de PDV:\")\n",
    "    print(perf_pdv)\n",
    "    \n",
    "    # Visualizar\n",
    "    fig = px.bar(\n",
    "        perf_pdv.reset_index(),\n",
    "        x='tipo_pdv',\n",
    "        y='MAE',\n",
    "        title=\"MAE por Tipo de PDV\",\n",
    "        color='MAE',\n",
    "        color_continuous_scale='RdYlBu_r'\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análise Temporal dos Erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance ao longo do tempo\n",
    "if 'data' in analysis_data.columns:\n",
    "    temporal_perf = analysis_data.groupby('data').agg({\n",
    "        'quantidade': 'sum',\n",
    "        'predicao': 'sum',\n",
    "        'erro_absoluto': 'mean',\n",
    "        'erro_percentual': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calcular WMAPE diário\n",
    "    temporal_perf['wmape_diario'] = (\n",
    "        np.abs(temporal_perf['quantidade'] - temporal_perf['predicao']) / \n",
    "        temporal_perf['quantidade'] * 100\n",
    "    )\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        subplot_titles=('Vendas Reais vs Preditas', 'WMAPE Diário'),\n",
    "        shared_xaxes=True\n",
    "    )\n",
    "    \n",
    "    # Vendas reais vs preditas\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=temporal_perf['data'], y=temporal_perf['quantidade'], \n",
    "                  mode='lines', name='Real', line=dict(color='blue')),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=temporal_perf['data'], y=temporal_perf['predicao'], \n",
    "                  mode='lines', name='Predito', line=dict(color='red')),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # WMAPE diário\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=temporal_perf['data'], y=temporal_perf['wmape_diario'], \n",
    "                  mode='lines', name='WMAPE', line=dict(color='green')),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(height=800, title_text=\"Análise Temporal da Performance\")\n",
    "    fig.show()\n",
    "    \n",
    "    print(f\"WMAPE médio diário: {temporal_perf['wmape_diario'].mean():.2f}%\")\n",
    "    print(f\"WMAPE mediano diário: {temporal_perf['wmape_diario'].median():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Análise de Outliers e Casos Extremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar casos com maior erro\n",
    "worst_predictions = analysis_data.nlargest(20, 'erro_absoluto')[[\n",
    "    'pdv', 'produto', 'quantidade', 'predicao', 'erro_absoluto', 'erro_percentual'\n",
    "]]\n",
    "\n",
    "print(\"Top 20 Piores Previsões (Maior Erro Absoluto):\")\n",
    "print(worst_predictions.round(2))\n",
    "\n",
    "# Análise de distribuição dos erros\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Distribuição Erro Absoluto', 'Distribuição Erro Percentual',\n",
    "                   'Erro vs Quantidade Real', 'Box Plot Erros por Faixa de Venda')\n",
    ")\n",
    "\n",
    "# Distribuição erro absoluto\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=analysis_data['erro_absoluto'], nbinsx=50, name='Erro Absoluto'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Distribuição erro percentual (limitado para visualização)\n",
    "erro_perc_limited = analysis_data['erro_percentual'].clip(upper=200)\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=erro_perc_limited, nbinsx=50, name='Erro Percentual'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Erro vs Quantidade\n",
    "sample_data = analysis_data.sample(n=min(5000, len(analysis_data)))  # Amostra para visualização\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=sample_data['quantidade'], y=sample_data['erro_absoluto'], \n",
    "              mode='markers', name='Erro vs Quantidade', opacity=0.6),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.update_layout(height=800, title_text=\"Análise de Distribuição dos Erros\", showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise por faixas de venda\n",
    "analysis_data['faixa_venda'] = pd.cut(\n",
    "    analysis_data['quantidade'], \n",
    "    bins=[0, 1, 5, 10, 50, 100, float('inf')],\n",
    "    labels=['0-1', '1-5', '5-10', '10-50', '50-100', '100+']\n",
    ")\n",
    "\n",
    "perf_faixa = analysis_data.groupby('faixa_venda').agg({\n",
    "    'quantidade': 'count',\n",
    "    'erro_absoluto': 'mean',\n",
    "    'erro_percentual': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "perf_faixa.columns = ['Num_Casos', 'MAE_Medio', 'MAPE_Medio']\n",
    "\n",
    "print(\"\\nPerformance por Faixa de Venda:\")\n",
    "print(perf_faixa)\n",
    "\n",
    "# Visualizar\n",
    "fig = px.bar(\n",
    "    perf_faixa.reset_index(),\n",
    "    x='faixa_venda',\n",
    "    y='MAE_Medio',\n",
    "    title=\"MAE Médio por Faixa de Venda\",\n",
    "    color='MAE_Medio',\n",
    "    color_continuous_scale='RdYlBu_r'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análise de Previsões para Janeiro/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simular previsões para janeiro/2023 (usando dados disponíveis)\n",
    "print(\"Análise das Previsões para Janeiro/2023...\")\n",
    "\n",
    "# Carregar previsões se disponíveis\n",
    "try:\n",
    "    predictions_jan = pd.read_csv('../predictions_example_20250910_153545.csv')\n",
    "    print(f\"Previsões carregadas: {predictions_jan.shape}\")\n",
    "    \n",
    "    # Estatísticas das previsões\n",
    "    print(\"\\nEstatísticas das Previsões:\")\n",
    "    print(f\"Total previsto: {predictions_jan['quantidade'].sum():,.0f}\")\n",
    "    print(f\"Média por PDV/SKU: {predictions_jan['quantidade'].mean():.2f}\")\n",
    "    print(f\"Mediana: {predictions_jan['quantidade'].median():.2f}\")\n",
    "    print(f\"Desvio padrão: {predictions_jan['quantidade'].std():.2f}\")\n",
    "    \n",
    "    # Distribuição das previsões\n",
    "    fig = px.histogram(\n",
    "        predictions_jan,\n",
    "        x='quantidade',\n",
    "        nbins=50,\n",
    "        title=\"Distribuição das Previsões para Janeiro/2023\"\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    # Previsões por semana\n",
    "    if 'semana' in predictions_jan.columns:\n",
    "        weekly_forecast = predictions_jan.groupby('semana')['quantidade'].sum()\n",
    "        \n",
    "        fig = px.bar(\n",
    "            x=weekly_forecast.index,\n",
    "            y=weekly_forecast.values,\n",
    "            title=\"Previsão Total por Semana - Janeiro/2023\",\n",
    "            labels={'x': 'Semana', 'y': 'Quantidade Total'}\n",
    "        )\n",
    "        fig.show()\n",
    "        \n",
    "        print(\"\\nPrevisão por Semana:\")\n",
    "        for semana, total in weekly_forecast.items():\n",
    "            print(f\"Semana {semana}: {total:,.0f} unidades\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Arquivo de previsões não encontrado. Execute o pipeline de predição primeiro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Validação de Qualidade das Previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validações de qualidade\n",
    "if 'predictions_jan' in locals():\n",
    "    print(\"=== VALIDAÇÕES DE QUALIDADE ===\")\n",
    "    \n",
    "    # 1. Valores negativos\n",
    "    negative_count = (predictions_jan['quantidade'] < 0).sum()\n",
    "    print(f\"Valores negativos: {negative_count} ({negative_count/len(predictions_jan)*100:.2f}%)\")\n",
    "    \n",
    "    # 2. Valores nulos\n",
    "    null_count = predictions_jan['quantidade'].isnull().sum()\n",
    "    print(f\"Valores nulos: {null_count} ({null_count/len(predictions_jan)*100:.2f}%)\")\n",
    "    \n",
    "    # 3. Valores extremos\n",
    "    q99 = predictions_jan['quantidade'].quantile(0.99)\n",
    "    extreme_count = (predictions_jan['quantidade'] > q99 * 3).sum()\n",
    "    print(f\"Valores extremos (>3x P99): {extreme_count} ({extreme_count/len(predictions_jan)*100:.2f}%)\")\n",
    "    \n",
    "    # 4. Distribuição por PDV\n",
    "    if 'pdv' in predictions_jan.columns:\n",
    "        pdv_counts = predictions_jan['pdv'].value_counts()\n",
    "        print(f\"\\nPDVs únicos: {predictions_jan['pdv'].nunique()}\")\n",
    "        print(f\"Registros por PDV - Média: {pdv_counts.mean():.1f}, Min: {pdv_counts.min()}, Max: {pdv_counts.max()}\")\n",
    "    \n",
    "    # 5. Distribuição por produto\n",
    "    if 'produto' in predictions_jan.columns:\n",
    "        produto_counts = predictions_jan['produto'].value_counts()\n",
    "        print(f\"\\nProdutos únicos: {predictions_jan['produto'].nunique()}\")\n",
    "        print(f\"Registros por produto - Média: {produto_counts.mean():.1f}, Min: {produto_counts.min()}, Max: {produto_counts.max()}\")\n",
    "    \n",
    "    # Comparação com padrões históricos\n",
    "    historical_stats = analysis_data['quantidade'].describe()\n",
    "    prediction_stats = predictions_jan['quantidade'].describe()\n",
    "    \n",
    "    comparison = pd.DataFrame({\n",
    "        'Histórico': historical_stats,\n",
    "        'Previsões': prediction_stats\n",
    "    }).round(2)\n",
    "    \n",
    "    print(\"\\nComparação Histórico vs Previsões:\")\n",
    "    print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Insights e Oportunidades de Melhoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de correlação entre erro e características\n",
    "correlation_analysis = analysis_data[[\n",
    "    'quantidade', 'erro_absoluto', 'erro_percentual'\n",
    "]].corr()\n",
    "\n",
    "print(\"Correlação entre Erro e Características:\")\n",
    "print(correlation_analysis.round(3))\n",
    "\n",
    "# Identificar padrões nos erros\n",
    "print(\"\\n=== INSIGHTS DOS ERROS ===\")\n",
    "\n",
    "# 1. Erro por magnitude de venda\n",
    "high_volume = analysis_data[analysis_data['quantidade'] > analysis_data['quantidade'].quantile(0.9)]\n",
    "low_volume = analysis_data[analysis_data['quantidade'] < analysis_data['quantidade'].quantile(0.1)]\n",
    "\n",
    "print(f\"MAPE - Alto volume (>P90): {high_volume['erro_percentual'].mean():.2f}%\")\n",
    "print(f\"MAPE - Baixo volume (<P10): {low_volume['erro_percentual'].mean():.2f}%\")\n",
    "\n",
    "# 2. Produtos com maior dificuldade de previsão\n",
    "if 'produto' in analysis_data.columns:\n",
    "    produto_difficulty = analysis_data.groupby('produto')['erro_percentual'].agg(['mean', 'count']).reset_index()\n",
    "    produto_difficulty = produto_difficulty[produto_difficulty['count'] >= 10]  # Mín 10 observações\n",
    "    difficult_products = produto_difficulty.nlargest(10, 'mean')\n",
    "    \n",
    "    print(\"\\nTop 10 Produtos Mais Difíceis de Prever:\")\n",
    "    for _, row in difficult_products.iterrows():\n",
    "        print(f\"Produto {row['produto']}: MAPE = {row['mean']:.1f}% ({row['count']} obs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Recomendações e Próximos Passos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== RESUMO EXECUTIVO ===\")\n",
    "print(f\"Modelo Final: {model_config['model_type']}\")\n",
    "print(f\"Performance Geral: WMAPE = {model_config['performance']['WMAPE']:.2f}%\")\n",
    "print(f\"Features Utilizadas: {len(model_config['features'])}\")\n",
    "print(f\"Dados de Treinamento: {len(analysis_data):,} registros\")\n",
    "\n",
    "if 'predictions_jan' in locals():\n",
    "    print(f\"Previsões Geradas: {len(predictions_jan):,} registros\")\n",
    "    print(f\"Volume Total Previsto: {predictions_jan['quantidade'].sum():,.0f} unidades\")\n",
    "\n",
    "print(\"\\n=== PRINCIPAIS INSIGHTS ===\")\n",
    "print(\"1. Features de lag são os preditores mais importantes\")\n",
    "print(\"2. Performance varia significativamente entre categorias\")\n",
    "print(\"3. Produtos de baixo volume têm maior erro percentual\")\n",
    "print(\"4. Sazonalidade é bem capturada pelo modelo\")\n",
    "print(\"5. Outliers impactam significativamente a performance\")\n",
    "\n",
    "print(\"\\n=== RECOMENDAÇÕES PARA MELHORIA ===\")\n",
    "print(\"1. Implementar modelos específicos por categoria\")\n",
    "print(\"2. Melhorar tratamento de produtos de baixo volume\")\n",
    "print(\"3. Adicionar features externas (feriados, promoções)\")\n",
    "print(\"4. Implementar ensemble mais sofisticado\")\n",
    "print(\"5. Usar técnicas de pós-processamento para outliers\")\n",
    "\n",
    "print(\"\\n=== PRÓXIMOS PASSOS ===\")\n",
    "print(\"1. Validar previsões com dados reais de janeiro\")\n",
    "print(\"2. Implementar monitoramento contínuo\")\n",
    "print(\"3. Retreinar modelo com novos dados\")\n",
    "print(\"4. Experimentar arquiteturas de deep learning\")\n",
    "print(\"5. Desenvolver sistema de alertas para anomalias\")\n",
    "\n",
    "print(\"\\n=== SUBMISSÕES RECOMENDADAS ===\")\n",
    "print(\"1. Modelo XGBoost otimizado (principal)\")\n",
    "print(\"2. Ensemble XGB + LightGBM (conservadora)\")\n",
    "print(\"3. Modelo com pós-processamento de outliers\")\n",
    "print(\"4. Versão com features reduzidas (robusta)\")\n",
    "print(\"5. Ensemble com Prophet para sazonalidade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar relatório de análise\n",
    "report_data = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'model_performance': model_config['performance'],\n",
    "    'data_summary': {\n",
    "        'training_records': len(analysis_data),\n",
    "        'features_used': len(model_config['features']),\n",
    "        'prediction_records': len(predictions_jan) if 'predictions_jan' in locals() else 0\n",
    "    },\n",
    "    'quality_checks': {\n",
    "        'negative_predictions': negative_count if 'predictions_jan' in locals() else 0,\n",
    "        'null_predictions': null_count if 'predictions_jan' in locals() else 0,\n",
    "        'extreme_predictions': extreme_count if 'predictions_jan' in locals() else 0\n",
    "    },\n",
    "    'insights': {\n",
    "        'top_feature_type': importance_by_type.index[0],\n",
    "        'worst_category_mape': perf_categoria['MAPE'].max() if 'perf_categoria' in locals() else None,\n",
    "        'best_category_mape': perf_categoria['MAPE'].min() if 'perf_categoria' in locals() else None\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('../data/processed/analysis_report.json', 'w') as f:\n",
    "    json.dump(report_data, f, indent=2)\n",
    "\n",
    "print(\"\\nRelatório de análise salvo em: ../data/processed/analysis_report.json\")\n",
    "print(\"Análise completa finalizada!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}